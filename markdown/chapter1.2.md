## Genetic variation {#sec:genetic-variation}

All living organisms have at least one thing in common: they have a genome. It will not look the same in different organisms, but the fundamentals are the same; there are four nucleotides, adenine (A), cytosine (C), guanine (G) and thymine (T) that form the molecule deoxyribonucleic acid, more commonly known as DNA. The DNA is organised into larger units called chromosomes, and the number of chromosomes vary from species to species. Humans, for example, are diploid organisms with two copies of each of the 23 chromosomes. European aspen (\textit{Populus tremula}) has 19 chromosomes, and is also a diploid organism. Being diploid means that every gene (and most other pieces of DNA for that matter) exist in two copies---two alleles. Whenever a cell divides, the genetic information has to be copied so that each of the daughter cells gets their own copy of the genome. In the process of copying the genome, perhaps *the* most fundamental property of biology manifests itself---erroneous copying of DNA. Without errors in this process, life as we know it would not exist. The errors introduce variation into the genetic material, and this variation can take different shapes. One type of mutation are single nucleotide polymorphisms (SNPs). As the name implies, this type of mutation changes a single base in the genome into another, and these are the type of mutations this thesis will solely focus on.

The central dogma of biology states that information flows from DNA to protein via messenger ribonucleic acid (mRNA), and information cannot flow from protein to DNA [@Crick1958]. When we talk about genes in this context, they are the parts of DNA that get transcribed into mRNA, and eventually translated into protein. Since the DNA alphabet only contains four letters, and the protein alphabet contains twenty letters, it is not a one-to-one relationship between mRNA and protein, but units of three nucleotides define one amino acid. This unit is called a codon. Proteins then act as the workers and the building blocks of the cell. The parts of the DNA that ends up being translated into protein are referred to as coding DNA, while other parts of the DNA is referred to as non-coding. Non-coding regions of the genome can also be transcribed and mostly have regulatory functions, but also act as structural elements [REF].

The definition above is fundamentally different from that of Mendel. In the mid 19th century, traits were believed to be blended when inherited, but Mendel's experiments showed that this was not always the case. He figured out that there must be different variants of some hidden factor that give rise to the differences in traits in the offspring generation. These factors are what we today refer to as genes, and the variants of these genes are alleles.

If mutations are introduced into coding regions of the genome, one of three things might happen: no effect at all (silent mutation), an amino acid substitution (mis-sense mutation), or the introduction of a stop codon and prematurely halt the translation process (non-sense mutation). Fifteen years ago, these types of mutations were in the lime light as everything outside of genes was largely discarded as "junk DNA". Since then, with the arrival of cheap high-throughput sequencing technologies, the focus has changed. Although "junk DNA" is not expressed and translated explicitly, it does facilitate the expression of genes and controls when and at what levels genes should be expressed. Gene expression will be presented in more detail in [@sec:gene-expression].

It might sound like regulatory DNA is something that has been discovered during the past fifteen years, but this is not the case at all. Regulatory elements in non-coding regions of the genome has been known and, to some extent, elucidated since at least the 1960's and the description of the regulation of the \textit{lac} operon by Fran√ßois Jacob and Jacques Monod [-@Jacob1961]. Even though these types of regulatory mechanisms have been known for a long time, it is only the developments in the past 10 years or so that has made large scale analysis of these types of regulatory mechanisms possible. This part of the genome is commonly referred to as the regulatory genome, and a plethora of studies have emerged that look at this in more detail, such as the ENCODE project that has the goal of finding all functional elements in the human genome [@Feingold2004]\footnote{One could also argue the projects like ENCODE help drive the technological development.}.

Given the diversity of the genome in terms of function, it is very hard to predict what effects on the phenotype different mutations will have. Mutations that change the protein sequence are easy to predict from simple sequence comparisons, but mutations that modify the gene regulation are much more difficult to predict from sequence alone, and they usually require extensive testing [@Stern2000]. New efforts, such as ENCODE, will enable researchers to more easily determine what effect mutations will have.

Humans and chimpanzees are said to share as much as 99% of the coding regions of the genome, and a lot of research has gone into finding out what could give rise to the differences between humans and chimpanzees. Several studies have found that most of the differences are located in non-coding regions, i.e\ potential regulatory regions [@Pollard2006; @Polavarapu2011]. So far, most of this variation has only been quantified; the effect of this variation is a completely different story. Genetic variation that give rise to changes in amino acid composition of proteins is easy to predict from sequence alone.  More and more efforts are being poured into the problem of predicting the effect of mutations in non-coding regions, and in the past few years we have seen the appearance of applications that try to predict the effect that SNPs will have on transcription factor binding affinity [@Macintyre2011; @Zuo2015] as well as general regulatory effects [@Makarov2012] based on existing databases. Most, if not all, of these efforts are however skewed towards the human genome which is something that becomes painfully obvious working with non-human data.

Another important source of genetic variation are gene and genome duplications. Returning to the comparison between humans and chimpanzees, there have been studies that have shown that gene duplication plays an important role in explaining phenotypic differences.

- What does the regulatory genome contain? Promoters, enhancers, ncRNA (all possible types).
- Genome duplication?

![Figure zooming in on the genetic variation component of [@fig:overview].](figures/placeholder.png){#fig:genetic-variation width=100%}

### Quantifying genetic variation

Technological advancements in the past two decades has led to a revolution in biology. Genome sequencing, i.e.\ the process of determining the order of nucleotides in the genome, has become very affordable. The $1000 human genome has been a long-time vision, and during my PhD period, this has become a reality [@CheckHayden2014]\footnote{Depending somewhat on how you count.}. It has never been this cheap or easy to get a the complete genome of an organism sequenced, and this clearly has huge potential for characterising the genetic variation in populations of individuals.

The process of sequencing an individual is to extract the DNA from the tissue of interest, randomly fragment the DNA, and then then determine the sequence of nucleotide for each DNA fragment. This is then performed until the required depth is reached, i.e.\ the mean number of sequenced fragments, or reads, for each position in the genome. There are a number of ways that genomic variation can be quantified from high-throughput sequencing data, but the most common way of doing this today is to align the sequencing reads against a reference genome, that is, a genome sequence that has already been determined. By aligning the reads to a common reference each position can be compared to the reference in order to identify regions that differ in relation to the reference. In the case of diploid organisms we expect to see two alleles for each locus. If the locus is homozygous, i.e.\ the two alleles are identical, then the reads originating from that locus should be idential. Conversely, if the locus is heterozygous, i.e.\ the two alleles are different, then the reads should be different from each other. Depending on the number of reads that support the variant and the quality of the reads, the variant will be detected, or called.

Different types of prior knowledge can be incorporated in the variant calling in order to increase precision, such as known variants from databases such as dbSNP [@Sherry2001]. Working with non-model, or even non-human organisms often mean that resources like this are not available, at least not in the same extent.

![Figure explaining the concept of sequence alignment?](figures/placeholder.png){#fig:seqalign width=100%}

<!-- Genetic variants occur with different frequencies within a population. In order to detect rare variants with reasonable statistical power, you need a correspondingly large sample size. In some parts of the literature, rare variants are believed to be the largest contributors to phenotypic variance. -->

These bullet points should probably go under association studies:

- Rare variants and information content
- Low effect variants: how many samples do you need? Human height study with 200k samples.
