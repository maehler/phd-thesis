## Integration of different types of data

From the sections on gene expression and association studies above, we see that it is possible to explain some of the variability in complex traits using these resources directly. The natural follow-up to this is whether we can gain even more from combining these sources of information. Between the genome and the phenotype of interest there are many regulatory steps: genes will be expressed (or not expressed), proteins might be degraded prematurely (or accumulate), and all these things act on each other in a complex network. A single analysis method, e.g.\ GWA, will simply not be able to capture the whole truth. You will get a genomic variant that is associated with your trait of interest, but everything in between will essentially be a black box. By integrating different types of data some more light can be shed on this matter.

Most GWAS variants found so far are located in non-coding regions of the genome, and it is thus hard to assign function to these variants. By combining GWA results with eQTL mapping results, genes can be assigned to these variants, and thus the phenotype, through guilt by association [@Musunuru2010; @Lappalainen2013; @Locke2015]. So far, most studies have focused only on protein coding genes which will result in non-coding GWA variants with no gene association. With RNA-Sequencing as the dominating technology for estimating gene expression together with the encouragement from the community to make data publicly available, there is however the possibility of redoing these studies when annotations of the regulatory genome improve.

To gain even more understanding as to how complex traits emerge, information from even more regulatory layers must be included. This can be done with two main approaches: multi-staged analysis or a meta-dimensional analysis [@Ritchie2015]. The multi-staged analysis is based on using data in a hierarchical manner, e.g.\ SNPs that are significantly associated with the phenotype of interest, and associate that subset of SNPs with gene expression levels, i.e.\ eQTL mapping. That way, the number of SNPs to consider is significantly decreased compared to a genome-wide eQTL mapping approach. The expression of the genes associated with genetic variants can then be used to investigate protein expression and perhaps look at a subset of a protein interaction network in order to get a more complete picture of the emergence of phenotypes. In a meta-dimensional analysis data from different layers are combined into a simultaneous analysis in order to consider multiple relationships at the same time, as opposed to the multi-staged analysis approach. For an in-depth review of data integration see [@Ritchie2015].

![Figure showing the different types of associations we have and what we could possibly get from combining these.](figures/data_integration.pdf){#fig:integration width=100%}

There are several challenges associated with this kind of data integration. The individual data sets themselves have their own issues to begin with. There are systematic biases, normalisation issues, and correlation structures that are not trivial to deal with.

In @sec:complexity, I mention that it is not feasible to do an exhaustive search for combinatorial effects. This problem becomes even more of a problem when including more data, but at the same time, it can help mitigate these issues. By layering the different types of data, things that most likely do not have an effect on the phenotype of interest can be excluded. By doing this, the search space can be limited drastically, and at one point it is actually feasible to test, if not all, many combinations of different layers of data.

- Dimensionality reduction of individual data sets as well. For example, SNPs can be in linkage disequilibrium, i.e.\ if you know the genotype of a particular SNP, any SNPs that are linked to this will not give you any more information and can thus be excluded/merged.
- Are we able to explain more by using different types of data that represent different layers of the (hidden) regulatory network.
- Difficult enough to get high quality information from a single data set. Each data set has their own issues such as confounding factors, and normalisation and dimensionality issues [@Ritchie2015].
